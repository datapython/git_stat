###  1:  R with Hadoop  ###
### there is a library called RHadoop by Revolutionary Analytics  ###
###  http://www.lecturemaker.com/2011/02/rhipe/?doNavDotNow=14&lecID=1#video  ##

###  2: Run R job in linux serser  ###
###  R CMD BATCH rjob.R , then there will be generated .Rout file  ###

###  3: R usrful commands  ###
attributes(mydata)  names(mydata)  class(mydata)  scan, search(),  data(), ls(), ls.str(), cat("\014")       
load   attach   getwd()  dir("/dir")   options()   history(max.show=Inf)    savehistory()  loadhistory()
save.image()    save(object)   source()   sink()

###  3: R: do like SAS proc summary  ###
read.csv("D:/hsong/SkyDrive/Dropbox/sampledata.csv")->data1
data.frame(data1)->data1
attach(data1)
names(data1)   ### check column names of data frame in R
aggregate(clicks,list(report_date,category_id),mean)   
### calculate the mean of clicks on report_date and category_id
###  similar to SAS: class report_date category_id; var clicks;


###  4: Interface from R to SAS  ###
system("C:\\Programe Files\\SAS\\SAS Foundation\\9.2\\SAS.exe
        C:\\my_r_files\\test.sas"
      )
###  Suppose test.sas is lke:
     proc summary data=sashelp.class mean sum;
     	var height;
     	class sex;
     	output out=results;
     run;
     
     proc export data=results outfile="C:\tmp\results.csv" DBMS=csv replace;
     	putname=yes;
     run;
###  Import the data to R:
import_sas_data <- read.csv("C:\\tmp\results.csv", sep=",", header=T)


###  5: calculate the statistics in subset and merge together
library(stats)
aggregate(cbind(ncases, ncontrols) ~ alcgp + tobgp, data = esoph, sum)->data1
aggregate(cbind(ncases, ncontrols) ~ alcgp , data = esoph, sum)->data2
merge(data1, data2, by.x="alcgp", by.y="alcgp")


###  6: R: pass parameters value from command line
### vi rscript.R and input:
args <- commandArgs(TRUE)
x=as.numeric(args)
x
y=sin(x)
y
## Then go to the command line and run: Rscript rscript.R 1 2 3 4 5 6 7
# the output will be:
# [1] 1 2 3 4 5 6 7
# [1]  0.8414710  0.9092974  0.1411200 -0.7568025 -0.9589243 -0.2794155  0.6569866


###  R: sort(x)=x[order(x)]  ####


###  Calculate Frequency in R(function table) and SAS(proc freq)   ###
read.csv("sampledata.csv",header=T)->data1
attach(data1)
names(data1)
table(PUBLISHER_ID,category_id)
# then you can cite the output as a matrix #


###  7: R: how to draw several graphs on one phrah (overlap)  ###
after plot() draw the first one, use par(new=TRUE), then draw the second one
sometimes it is better to use the same axis notations like all plots add the limitations as plot(¡­¡­¡­¡­,xlim=c))


###  8:  logistic regression

read.csv("D:\\hsong\\Desktop\\qcs.csv")->qsc1

##  pick three columns we wanted
qsc=qsc1[,c("deals", "c_category_id", "payer_id")]

attach(qsc)

## change value in data.frame to factors
qsc$c_category_id<-as.factor(c_category_id)

qsc$payer_id<-as.factor(payer_id)

detach(qsc)

##  logistic regression and xs are factors
glm(deals~payer_id+c_category_id, family=binomial, data=qsc)

##  subset from data.frame by picl levels within factors
subset(qsc,payer_id %in% (550))->subset1


###  9:  usage of by: an example of weighted mean (it's better to use library(plyr))
x=c( -0.14782,0.62819, -1.73016,  0.04899,  0.48055,  1.52336,  0.76867,  0.29333, -1.18384,  0.96684,  0.50848,  2.25771,  0.14574,  0.50290,  0.26342)
b=c(1:5,1:5,seq(1,9,by=2))
f=rep(c(1,2,3),each=5)
df=as.data.frame(cbind(x,b,f))
by(df, list(df$f), function(subset) weighted.mean(subset$x, subset$b))
###  use library(plyr)
library(plyr)
ddply(df,.(f), function(x) data.frame(wret=weighted.mean(x$x,x$b)))



###  10: plot and then label each point
library(foreign)
read.spss("http://dl.dropbox.com/u/10684315/ucla_reg/crime.sav",to.data.frame=T)->crime
## plot crime vs single and add state as the label to each point
plot(crime$pctmetro,crime$crime)
text(crime$pctmetro,crime$crime,crime$state,cex=.5,pos=2)


###  11: add a new plot on the existed plot
names(crime)<-tolower(names(crime))
row.names(crime)<-crime$state
lm(crime~pctmetro+pctsingle+poverty+single,crime)->crime_reg1
library(car)
dfbetas(crime_reg1)->dfb_reg1
as.data.frame(dfb_reg1)->df_dfb_reg1
plot(df_dfb_reg1$pctmetro,col="red")
par(new=T)
plot(df_dfb_reg1$single,col="green")
###  it can also be done by lines or points, which will draw graph in the existed plot
plot(df_dfb_reg1$pctmetro,col="red")
points(df_dfb_reg1$single,col="green")


###  12: usful functions after linear regression
reg1=lm(y~x, data)
plot(hatvalues(reg1),rstudent(reg1),cex=.5,col="red")
cd=sqrt(cooks.distance(crime_reg1))
vif(reg1)


###  13: merge multiple dataframe(tables) together by multiple columns
DF1<-data.frame(var1=letters[1:5],a=rnorm(5), b=rnorm(5), c=rnorm(5))
DF2<-data.frame(var1=letters[3:7],a=rnorm(5), b=rnorm(5), c=rnorm(5))
DF3<-data.frame(var1=letters[6:10],a=rnorm(5), b=rnorm(5), c=rnorm(5))
DF4<-data.frame(var1=letters[8:12],a=rnorm(5), b=rnorm(5), c=rnorm(5))
DF<-DF1
## this one not work
for (.df in (list(DF2, DF3, DF4))){
	DF<-merge(DF,.df,by.x="var1",by.y="var1",all=T,suffixes=c("", ""))
}
## this one works
DF <- DF1
for ( .df in list(DF2,DF3,DF4) ) {
	DF <-merge(DF,.df,by.x="var1", by.y="var1", all=T)
        names(DF)[-1] <- paste(names(DF)[-1], 2:length(names(DF)))
}
names(DF) <- sub("[[:space:]].+$", "", names(DF), perl=T)


###  14: drop columns, date convert, aggregate and merge
# remove all data in workspace
rm(list=ls())
# clear the screen
cat("\014")
# read in data and treat . as missing(NA)
read.csv("D:\\hsong\\SkyDrive\\r_temp\\visitnew_summary.csv",na.string='.',stringsAsFactors=F,header=T)->visnew
head(visnew)
visnew$report_date<-as.Date(visnew$report_date,"%d-%b-%y")
# check the class of each variable in the table
sapply(visnew,class)
# lowcase all column names
names(visnew)<-tolower(names(visnew))
# drop two unnecessary columns, or use  subset(visnew, select=-c(x_type_, x_freq_))
visnew[,!(names(visnew) %in% c("x_type_", "x_freq_"))]->visnews
head(visnews)

## aggregate data
aggregate(cbind(visits, revenue, clicks)~report_date,visnew,sum)->sum1
## set the missing value as 0: visnew[is.na(visnew)]<-0 
aggregate(cbind(visits, revenue, clicks)~report_date+publisher_id+category_id, visnew, sum)->sum2
## be careful, if don't use na.rm, then the return value below will be NA
aggregate(visnew[,c("visits","revenue","clicks")],by=list(rpt_dt=visnew$report_date,pub_id=visnew$publisher_id),sum,na.rm=T)
## how to merge two df by multiple variables
df29=sum2[sum2$publisher_id==29,]
df304=sum2[sum2$publisher_id==304,]
merge(df29,df304,by=c("report_date","category_id"))


###  15: sort data
# sorting examples using the mtcars dataset
attach(mtcars)
# sort by mpg
newdata <- mtcars[order(mpg),] 
# sort by mpg and cyl
newdata <- mtcars[order(mpg, cyl),]
#sort by mpg (ascending) and cyl (descending)
newdata <- mtcars[order(mpg, -cyl),] 
detach(mtcars)


###  16: subset of a data with subset funtion
# pick the obs with cyl==4 and gear==4, and pick cols as below
subset(mtcars, cyl==4 & gear==4, select=c("mpg", "cyl", "gear", "hp", "wt"))
# drop the col hp and wt
subset(mtcars, select=-c(hp, wt))
# pick the columns from mpg to am
subset(mtcars, select=mpg:am)


###  17: use gl to generate factor levels
gl(n, k, length = n*k, labels = 1:n, ordered = FALSE)
f1=gl(n=3,k=1,length=30, labels=c("A","B","C"))
f2=gl(n=5,k=2,length=30, labels=1:5)


###  18: Frequencies and Crosstabs: table, xtabs, ftable, crosstable
attach(mtcars)
tab1<-table(cyl, gear, carb)
ftable(tab1)
tab2<-xtabs(~cyl+gear+carb)
ftable(tab2)
detach(mtcars)


###  19: regular expression
# grep to capture the presence of a char
grep("apple", c("crab apple", "Apple jack", "apple sauce"))
grep("apple", c("crab apple", "Apple jack", "apple sauce"), ignore.case=T)
# strsplit to break string into small pieces
text="Today is Monday, all the people are very happy to work"
strsplit(text, ' ')
# regexpr gregexpr to pinpint nad extract the position of a string in a regular expression
regexpr('[a-z]', c("today is monday", "007 is interesting", "2955 univ. dr", "apple store"))
# replace and substitute
price=c("$110,112.00", "$3,567.23", "$99,989.00", "1,028.98")
sub('[$,]','',price)
## compare to SAS
 a) paste("X", 1, sep='_')        <------->  cat   or   || 
 b) substring(state.name,1,2)     <------->  substr(statename,1,2)
 c) strsplit(text, ' ')           <------->  scan(text, 1, ' ')
 d) grep('pop', names(LifeCycleSavings))   <------->  index( , )
 e) regexpr('[a-z][A-Z]', names(LifeCycleSavings))  <------->   
 f) gsub('[$,]', '', "$11,110.19")    <-------> 


###  20: migrate data from SAS to R
# save sas data in transport format
libname temp xport "/home/sas2r";
data temp.mydata;
	set my_sas_data;
run;
# in R, read in the data with sasxport.get function from library(Hmisc)
library(Hmisc)
mydata<-sasxport.get("/home/sas2r")
# to export the data to an txt file, delimited by Tab
write.table(mydata, "/home/rout", sep="\t")
=======
# The two *sub functions differ only in that sub replaces only the first occurrence of a pattern whereas gsub replaces all occurrences.










